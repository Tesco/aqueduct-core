package com.tesco.aqueduct.pipe.storage;

import com.opentable.db.postgres.junit.EmbeddedPostgresRules;
import com.opentable.db.postgres.junit.SingleInstancePostgresRule;
import com.tesco.aqueduct.pipe.api.Message;
import com.tesco.aqueduct.pipe.api.Reader;
import groovy.sql.Sql;
import org.openjdk.jmh.annotations.*;

import javax.sql.DataSource;
import java.io.File;
import java.net.URISyntaxException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.sql.SQLException;
import java.sql.Timestamp;
import java.time.ZonedDateTime;
import java.util.*;
import java.util.stream.IntStream;

public class PostgresqlStorageBenchmark extends StorageSpec  {

    private SingleInstancePostgresRule pg = EmbeddedPostgresRules.singleInstance();

    private static Sql sql;
    private PostgresqlStorage storage;
    private DataSource dataSource;

    private static final long CLUSTER_A = 1L;

    private long retryAfter = 5000;
    private long batchSize = 1000;

    PostgresqlStorageBenchmark() throws SQLException {
        dataSource = pg.getEmbeddedPostgres().getPostgresDatabase();

        sql = new Sql(dataSource.getConnection());

        sql.execute(
        "DROP TABLE IF EXISTS EVENTS;" +
        "DROP TABLE IF EXISTS CLUSTERS;" +
        "CREATE TABLE EVENTS(" +
        "    msg_offset bigint PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY NOT NULL," +
        "    msg_key varchar NOT NULL," +
        "    content_type varchar NOT NULL," +
        "    type varchar NOT NULL," +
        "    created_utc timestamp NOT NULL," +
        "    tags JSONB NULL," +
        "    data text NULL," +
        "    event_size int NOT NULL," +
        "    cluster_id BIGINT NOT NULL DEFAULT 1" +
        ");" +
        "CREATE TABLE CLUSTERS(" +
        "    cluster_id BIGSERIAL PRIMARY KEY NOT NULL," +
        "    cluster_uuid VARCHAR NOT NULL" +
        ");" +
        "INSERT INTO CLUSTERS (cluster_uuid) VALUES ('NONE');"
        );

        storage = new PostgresqlStorage(this.dataSource, limit, retryAfter, batchSize);
    }

    @State(Scope.Benchmark)
    public static class PostgresDatabaseState {

        List<Long> clusterIds;

        @Setup(Level.Trial)
        public void doSetup() throws Exception {

            clusterIds = new ArrayList<>(100);

            for (int i=0; i<100; i++) {
                clusterIds.add(insertCluster("Cluster_" + i));
            }

            Random randomizer = new Random();

            Path path = Paths.get(this.getClass().getClassLoader().getResource("message_content.json").toURI());
            String messageContent = new String(Files.readAllBytes(path));

            for (int i=0; i<=100000; i++) {
                Long clusterId = clusterIds.get(randomizer.nextInt(100));
                insertWithCluster(
                    new Message("type1", "key_" + i, "content-type", Long.valueOf(i), ZonedDateTime.parse("2000-12-01T10:00:00Z"), messageContent),
                    clusterId);
            }
        }

        @TearDown(Level.Iteration)
        public void doTearDown() {
        }

        void insertWithCluster(Message msg, Long clusterId) throws SQLException {
            Timestamp time = Timestamp.valueOf(msg.getCreated().toLocalDateTime());
            sql.execute(
                    "INSERT INTO EVENTS(msg_offset, msg_key, content_type, type, created_utc, data, event_size, cluster_id) VALUES(?,?,?,?,?,?,?,?);",
                    new Object[] {msg.getOffset(), msg.getKey(), msg.getContentType(), msg.getType(), time, msg.getData(), 0, clusterId});
        }

        Long insertCluster(String clusterUuid) throws SQLException {
            return (Long)sql.executeInsert("INSERT INTO CLUSTERS(cluster_uuid) VALUES (?);", new Object[] {clusterUuid}).get(0).get(0);
        }

        Message message(Long offset, String type, String key, String contentType, ZonedDateTime created, String data) {
            return new Message(
                type,
                key,
                contentType,
                offset,
                created,
                data
            );
        }
    }

    @Benchmark @BenchmarkMode(Mode.AverageTime)
    public void eventsQueryWithoutTypeFiltering() {
        storage.read(Collections.emptyList(), 0, Arrays.asList("Cluster_A", "Cluster_B", "Cluster_C"));
    }

    @Override
    public Reader getStorage() {
        return null;
    }

    @Override
    public void insert(Message msg) {

    }

    @Override
    public Message message(Long offset, String type, String key, String contentType, ZonedDateTime created, String data) {
        return null;
    }
}
